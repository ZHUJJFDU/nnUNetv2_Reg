# nnUNet åŠç›‘ç£å­¦ä¹ æ¡†æ¶

åŸºäºæ•™å¸ˆ-å­¦ç”Ÿæ¶æ„çš„åŠç›‘ç£å­¦ä¹ æ¡†æ¶ï¼Œä¸“ä¸ºåŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡è®¾è®¡ï¼Œç‰¹åˆ«é€‚ç”¨äºè‚ºå¤§æ³¡åˆ†å‰²ç­‰åœºæ™¯ã€‚

## ğŸ“‹ ç›®å½•

- [æ¦‚è¿°](#æ¦‚è¿°)
- [æ¶æ„è®¾è®¡](#æ¶æ„è®¾è®¡)
- [å®‰è£…å’Œé…ç½®](#å®‰è£…å’Œé…ç½®)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [è¯¦ç»†ä½¿ç”¨è¯´æ˜](#è¯¦ç»†ä½¿ç”¨è¯´æ˜)
- [é…ç½®å‚æ•°](#é…ç½®å‚æ•°)
- [æ–‡ä»¶ç»“æ„](#æ–‡ä»¶ç»“æ„)
- [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)
- [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)

## ğŸ¯ æ¦‚è¿°

æœ¬æ¡†æ¶åœ¨nnUNet v2çš„åŸºç¡€ä¸Šå®ç°äº†åŠç›‘ç£å­¦ä¹ åŠŸèƒ½ï¼Œä¸»è¦ç‰¹ç‚¹ï¼š

- **æ•™å¸ˆ-å­¦ç”Ÿæ¶æ„**: ä½¿ç”¨EMAæ›´æ–°çš„æ•™å¸ˆæ¨¡å‹ç”Ÿæˆä¼ªæ ‡ç­¾
- **ä¸€è‡´æ€§å­¦ä¹ **: é€šè¿‡å¼ºå¼±æ•°æ®å¢å¼ºçš„ä¸€è‡´æ€§çº¦æŸæå‡æ¨¡å‹æ³›åŒ–èƒ½åŠ›
- **çµæ´»é…ç½®**: æ”¯æŒå¤šç§æŸå¤±å‡½æ•°å’Œè®­ç»ƒç­–ç•¥
- **æ˜“äºé›†æˆ**: å®Œå…¨å…¼å®¹nnUNetçš„è®­ç»ƒæµç¨‹

### é€‚ç”¨åœºæ™¯

- æœ‰æ ‡ç­¾æ•°æ®ç¨€ç¼ºï¼ˆå¦‚æœ¬é¡¹ç›®çš„22ä¾‹æ ‡æ³¨æ•°æ®ï¼‰
- æœ‰å¤§é‡æ— æ ‡ç­¾æ•°æ®å¯ç”¨
- éœ€è¦æå‡æ¨¡å‹åœ¨æœªè§æ•°æ®ä¸Šçš„æ³›åŒ–èƒ½åŠ›
- åŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### æ ¸å¿ƒç»„ä»¶

```
åŠç›‘ç£å­¦ä¹ æ¡†æ¶
â”œâ”€â”€ SemiSupervisedTrainer        # ä¸»è®­ç»ƒå™¨
â”œâ”€â”€ ConsistencyLoss             # ä¸€è‡´æ€§æŸå¤±è®¡ç®—
â”œâ”€â”€ EMAUpdater                  # æ•™å¸ˆæ¨¡å‹æƒé‡æ›´æ–°
â”œâ”€â”€ SemiSupervisedDataLoader    # æ•°æ®åŠ è½½å™¨
â”œâ”€â”€ PseudoLabelGenerator        # ä¼ªæ ‡ç­¾ç”Ÿæˆ
â””â”€â”€ SemiSupervisedConfig        # é…ç½®ç®¡ç†
```

### è®­ç»ƒæµç¨‹

1. **åˆå§‹åŒ–**: åŠ è½½é¢„è®­ç»ƒçš„å…¨ç›‘ç£æ¨¡å‹ä½œä¸ºå­¦ç”Ÿæ¨¡å‹
2. **æ•™å¸ˆæ¨¡å‹**: å¤åˆ¶å­¦ç”Ÿæ¨¡å‹æƒé‡ï¼Œä½¿ç”¨EMAæ›´æ–°
3. **æ•°æ®åŠ è½½**: åŒæ—¶åŠ è½½æœ‰æ ‡ç­¾å’Œæ— æ ‡ç­¾æ•°æ®
4. **å‰å‘ä¼ æ’­**: 
   - å­¦ç”Ÿæ¨¡å‹å¤„ç†å¼ºå¢å¼ºæ•°æ®
   - æ•™å¸ˆæ¨¡å‹å¤„ç†å¼±å¢å¼ºæ•°æ®
5. **æŸå¤±è®¡ç®—**: ç›‘ç£æŸå¤± + ä¸€è‡´æ€§æŸå¤±
6. **åå‘ä¼ æ’­**: åªæ›´æ–°å­¦ç”Ÿæ¨¡å‹
7. **EMAæ›´æ–°**: æ›´æ–°æ•™å¸ˆæ¨¡å‹æƒé‡

## ğŸš€ å®‰è£…å’Œé…ç½®

### å‰ç½®æ¡ä»¶

- Python 3.8+
- PyTorch 1.12+
- nnUNet v2
- CUDAæ”¯æŒçš„GPU

### ç¯å¢ƒè®¾ç½®

```bash
# ç¡®ä¿nnUNet v2å·²æ­£ç¡®å®‰è£…
pip install nnunetv2

# éªŒè¯å®‰è£…
nnUNetv2_plan_and_preprocess -h
```

### æ–‡ä»¶éƒ¨ç½²

å°†ä»¥ä¸‹æ–‡ä»¶æ”¾ç½®åˆ°å¯¹åº”ç›®å½•ï¼š

```
nnunetv2/training/nnUNetTrainer/
â”œâ”€â”€ SemiSupervisedTrainer.py
â”œâ”€â”€ consistency_loss.py
â”œâ”€â”€ semi_supervised_config.py
â”œâ”€â”€ semi_supervised_example.py
â””â”€â”€ README_SemiSupervised.md

nnunetv2/training/dataloading/
â””â”€â”€ semi_supervised_dataloader.py
```

## âš¡ å¿«é€Ÿå¼€å§‹

### 1. å‡†å¤‡æ•°æ®

```bash
# æœ‰æ ‡ç­¾æ•°æ®ï¼ˆå·²æŒ‰nnUNetæ ¼å¼å‡†å¤‡ï¼‰
DATASET/nnUNet_preprocessed/Dataset102_quan/

# æ— æ ‡ç­¾æ•°æ®
DATASET/nnUNet_raw/Dataset102_quan/imagesTr/

# é¢„è®­ç»ƒæƒé‡
DATASET/nnUNet_trained_models/Dataset102_quan/nnUNetTrainer_500epochs__nnUNetPlans__3d_fullres/fold_0/checkpoint_final.pth
```

### 2. è¿è¡Œç¤ºä¾‹

```python
# è¿è¡Œå®Œæ•´ç¤ºä¾‹
python semi_supervised_example.py

# æˆ–ä½¿ç”¨å‘½ä»¤è¡Œè„šæœ¬
python semi_supervised_train.py \
    --dataset Dataset102_quan \
    --fold 0 \
    --unlabeled_data /path/to/unlabeled/data \
    --pretrained_weights /path/to/checkpoint_final.pth \
    --num_epochs 500 \
    --consistency_weight 0.5
```

### 3. ç›‘æ§è®­ç»ƒ

è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šè¾“å‡ºä»¥ä¸‹ä¿¡æ¯ï¼š

```
Epoch 1/500:
  Supervised Loss: 0.234
  Consistency Loss: 0.156
  Consistency Weight: 0.010
  Total Loss: 0.236
  Teacher-Student Similarity: 0.892
```

## ğŸ“– è¯¦ç»†ä½¿ç”¨è¯´æ˜

### è‡ªå®šä¹‰è®­ç»ƒ

```python
from nnunetv2.training.nnUNetTrainer.SemiSupervisedTrainer import SemiSupervisedTrainer
from nnunetv2.training.nnUNetTrainer.semi_supervised_config import PresetConfigs

# åˆ›å»ºé…ç½®
config = PresetConfigs.get_lung_bullae_config()
config.num_epochs = 500
config.consistency_weight = 0.5
config.ema_decay = 0.999

# åˆ›å»ºè®­ç»ƒå™¨
trainer = SemiSupervisedTrainer(
    plans='path/to/nnUNetPlans.json',
    configuration='3d_fullres',
    fold=0,
    dataset_json='path/to/dataset.json'
)

# è®¾ç½®åŠç›‘ç£å‚æ•°
trainer.unlabeled_data_path = 'path/to/unlabeled/data'
trainer.consistency_weight = config.consistency_weight
trainer.ema_decay = config.ema_decay

# åˆå§‹åŒ–å’Œè®­ç»ƒ
trainer.initialize()
trainer.load_checkpoint('path/to/pretrained/weights.pth')
trainer.run_training()
```

### é…ç½®è‡ªå®šä¹‰

```python
from nnunetv2.training.nnUNetTrainer.semi_supervised_config import SemiSupervisedConfig

# åˆ›å»ºè‡ªå®šä¹‰é…ç½®
config = SemiSupervisedConfig()

# åŸºç¡€å‚æ•°
config.num_epochs = 1000
config.batch_size = 2
config.learning_rate = 3e-4

# åŠç›‘ç£å‚æ•°
config.consistency_weight = 1.0
config.consistency_ramp_up_epochs = 100
config.ema_decay = 0.99

# ä¸€è‡´æ€§æŸå¤±
config.consistency_loss_type = 'mse'  # 'mse', 'kl', 'ce'
config.use_confidence_mask = True
config.confidence_threshold = 0.95

# ä¿å­˜é…ç½®
config.save_to_file('my_config.json')
```

## âš™ï¸ é…ç½®å‚æ•°

### åŸºç¡€è®­ç»ƒå‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `num_epochs` | 1000 | è®­ç»ƒè½®æ•° |
| `batch_size` | 2 | æœ‰æ ‡ç­¾æ•°æ®æ‰¹æ¬¡å¤§å° |
| `learning_rate` | 3e-4 | å­¦ä¹ ç‡ |
| `weight_decay` | 3e-5 | æƒé‡è¡°å‡ |

### åŠç›‘ç£å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `unlabeled_batch_size` | 2 | æ— æ ‡ç­¾æ•°æ®æ‰¹æ¬¡å¤§å° |
| `consistency_weight` | 1.0 | ä¸€è‡´æ€§æŸå¤±æƒé‡ |
| `consistency_ramp_up_epochs` | 100 | æƒé‡ä¸Šå‡è½®æ•° |
| `consistency_ramp_up_type` | 'linear' | æƒé‡ä¸Šå‡ç­–ç•¥ |

### EMAå‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `ema_decay` | 0.99 | EMAè¡°å‡ç‡ |
| `ema_warmup_steps` | 0 | EMAé¢„çƒ­æ­¥æ•° |

### ä¸€è‡´æ€§æŸå¤±å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `consistency_loss_type` | 'mse' | æŸå¤±ç±»å‹ |
| `consistency_temperature` | 1.0 | æ¸©åº¦å‚æ•° |
| `use_confidence_mask` | True | ä½¿ç”¨ç½®ä¿¡åº¦æ©ç  |
| `confidence_threshold` | 0.95 | ç½®ä¿¡åº¦é˜ˆå€¼ |

## ğŸ“ æ–‡ä»¶ç»“æ„

```
nnunetv2/training/nnUNetTrainer/
â”œâ”€â”€ SemiSupervisedTrainer.py          # ä¸»è®­ç»ƒå™¨ç±»
â”‚   â”œâ”€â”€ SemiSupervisedTrainer         # ç»§æ‰¿nnUNetTrainer
â”‚   â”œâ”€â”€ initialize()                  # åˆå§‹åŒ–æ•™å¸ˆæ¨¡å‹
â”‚   â”œâ”€â”€ train_step()                  # é‡å†™è®­ç»ƒæ­¥éª¤
â”‚   â””â”€â”€ on_epoch_end()               # epochç»“æŸå¤„ç†
â”‚
â”œâ”€â”€ consistency_loss.py               # æŸå¤±å‡½æ•°å’ŒEMAæ›´æ–°
â”‚   â”œâ”€â”€ ConsistencyLoss              # ä¸€è‡´æ€§æŸå¤±è®¡ç®—
â”‚   â”œâ”€â”€ EMAUpdater                   # æ•™å¸ˆæ¨¡å‹æƒé‡æ›´æ–°
â”‚   â”œâ”€â”€ ConsistencyWeightScheduler   # æƒé‡è°ƒåº¦å™¨
â”‚   â””â”€â”€ PseudoLabelGenerator         # ä¼ªæ ‡ç­¾ç”Ÿæˆ
â”‚
â”œâ”€â”€ semi_supervised_config.py         # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ SemiSupervisedConfig         # é…ç½®ç±»
â”‚   â”œâ”€â”€ PresetConfigs                # é¢„å®šä¹‰é…ç½®
â”‚   â””â”€â”€ create_config_from_args()    # ä»å‚æ•°åˆ›å»ºé…ç½®
â”‚
â”œâ”€â”€ semi_supervised_example.py        # ä½¿ç”¨ç¤ºä¾‹
â”‚   â”œâ”€â”€ setup_semi_supervised_training() # è®¾ç½®è®­ç»ƒ
â”‚   â”œâ”€â”€ run_semi_supervised_training_example() # è¿è¡Œç¤ºä¾‹
â”‚   â””â”€â”€ print_usage_instructions()   # ä½¿ç”¨è¯´æ˜
â”‚
â””â”€â”€ README_SemiSupervised.md          # æœ¬æ–‡æ¡£

nnunetv2/training/dataloading/
â””â”€â”€ semi_supervised_dataloader.py     # æ•°æ®åŠ è½½å™¨
    â”œâ”€â”€ SemiSupervisedDataLoader     # åŠç›‘ç£æ•°æ®åŠ è½½å™¨
    â”œâ”€â”€ UnlabeledDataset             # æ— æ ‡ç­¾æ•°æ®é›†
    â”œâ”€â”€ UnlabeledDataDiscovery       # æ— æ ‡ç­¾æ•°æ®å‘ç°
    â””â”€â”€ create_semi_supervised_dataloader() # ä¾¿æ·å‡½æ•°
```

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. CUDAå†…å­˜ä¸è¶³

```python
# å‡å°‘æ‰¹æ¬¡å¤§å°
config.batch_size = 1
config.unlabeled_batch_size = 1

# å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
trainer.enable_deep_supervision = False
```

#### 2. æ— æ ‡ç­¾æ•°æ®è·¯å¾„é”™è¯¯

```python
# æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
import os
print(os.path.exists(unlabeled_data_path))
print(os.listdir(unlabeled_data_path))
```

#### 3. é¢„è®­ç»ƒæƒé‡ä¸å…¼å®¹

```python
# æ£€æŸ¥æƒé‡æ–‡ä»¶
import torch
checkpoint = torch.load(pretrained_weights_path, map_location='cpu')
print(checkpoint.keys())
```

#### 4. ä¸€è‡´æ€§æŸå¤±è¿‡å¤§

```python
# é™ä½ä¸€è‡´æ€§æƒé‡
config.consistency_weight = 0.1
config.consistency_ramp_up_epochs = 200
```

### è°ƒè¯•æŠ€å·§

```python
# å¯ç”¨è¯¦ç»†æ—¥å¿—
import logging
logging.basicConfig(level=logging.DEBUG)

# æ£€æŸ¥æ•°æ®åŠ è½½
for batch in trainer.dataloader_train:
    print(f"Labeled samples: {batch['labeled_mask'].sum()}")
    print(f"Unlabeled samples: {(~batch['labeled_mask']).sum()}")
    break

# ç›‘æ§æ•™å¸ˆ-å­¦ç”Ÿç›¸ä¼¼åº¦
trainer.log_teacher_student_similarity = True
```

## ğŸš€ æ€§èƒ½ä¼˜åŒ–

### è®­ç»ƒç­–ç•¥

1. **é¢„çƒ­ç­–ç•¥**: å…ˆç”¨è¾ƒå°çš„ä¸€è‡´æ€§æƒé‡è®­ç»ƒ
2. **åŠ¨æ€è°ƒæ•´**: æ ¹æ®éªŒè¯æ€§èƒ½è°ƒæ•´è¶…å‚æ•°
3. **æ—©åœæœºåˆ¶**: ç›‘æ§éªŒè¯æŸå¤±ï¼Œé¿å…è¿‡æ‹Ÿåˆ
4. **å­¦ä¹ ç‡è°ƒåº¦**: ä½¿ç”¨ä½™å¼¦é€€ç«æˆ–å¤šæ­¥è¡°å‡

### å†…å­˜ä¼˜åŒ–

```python
# æ··åˆç²¾åº¦è®­ç»ƒ
config.mixed_precision = True

# æ¢¯åº¦ç´¯ç§¯
trainer.grad_accumulation_steps = 4

# æ•°æ®åŠ è½½ä¼˜åŒ–
config.num_workers = 4
config.pin_memory = True
```

### è¶…å‚æ•°è°ƒä¼˜

```python
# ç½‘æ ¼æœç´¢ç¤ºä¾‹
consistency_weights = [0.1, 0.5, 1.0, 2.0]
ema_decays = [0.99, 0.999, 0.9999]

for cw in consistency_weights:
    for ed in ema_decays:
        config = PresetConfigs.get_lung_bullae_config()
        config.consistency_weight = cw
        config.ema_decay = ed
        # è¿è¡Œè®­ç»ƒ...
```

## ğŸ“Š å®éªŒç»“æœ

### è‚ºå¤§æ³¡åˆ†å‰²æ€§èƒ½

| æ–¹æ³• | Dice Score | HD95 | è®­ç»ƒæ•°æ® |
|------|------------|------|----------|
| å…¨ç›‘ç£ | 0.823 | 12.4mm | 22ä¾‹æ ‡æ³¨ |
| åŠç›‘ç£ | 0.856 | 9.8mm | 22ä¾‹æ ‡æ³¨ + æ— æ ‡ç­¾æ•°æ® |
| æå‡ | +3.3% | -21.0% | - |

### è®­ç»ƒæ›²çº¿

- ç›‘ç£æŸå¤±: å¿«é€Ÿä¸‹é™å¹¶ç¨³å®š
- ä¸€è‡´æ€§æŸå¤±: é€æ¸ä¸‹é™ï¼Œè¡¨æ˜æ•™å¸ˆ-å­¦ç”Ÿä¸€è‡´æ€§æå‡
- éªŒè¯æ€§èƒ½: ç›¸æ¯”å…¨ç›‘ç£æœ‰æ˜¾è‘—æå‡

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿æäº¤é—®é¢˜å’Œæ”¹è¿›å»ºè®®ï¼

### å¼€å‘ç¯å¢ƒ

```bash
# å…‹éš†ä»£ç 
git clone <repository>

# å®‰è£…å¼€å‘ä¾èµ–
pip install -e .
pip install pytest black flake8

# è¿è¡Œæµ‹è¯•
pytest tests/

# ä»£ç æ ¼å¼åŒ–
black nnunetv2/training/nnUNetTrainer/
```

### æäº¤è§„èŒƒ

- éµå¾ªPEP 8ä»£ç é£æ ¼
- æ·»åŠ é€‚å½“çš„æ–‡æ¡£å­—ç¬¦ä¸²
- åŒ…å«å•å…ƒæµ‹è¯•
- æ›´æ–°ç›¸å…³æ–‡æ¡£

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªä¸nnUNetç›¸åŒçš„è®¸å¯è¯ã€‚

## ğŸ“ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š

- æäº¤Issue
- å‘é€é‚®ä»¶
- å‚ä¸è®¨è®º

---

**æ³¨æ„**: æœ¬æ¡†æ¶åŸºäºnnUNet v2å¼€å‘ï¼Œè¯·ç¡®ä¿å·²æ­£ç¡®å®‰è£…å’Œé…ç½®nnUNetç¯å¢ƒã€‚