## 目标
- 构建稳定的三阶段架构：全监督分割预训练 → 师生半监督训练 → 双解码器回归微调
- 修复半监督实现中的数据加载、增强与一致性权重调度问题
- 清理并修复双解码器回归训练器（路径、数据集、验证与网络对接）

## 已发现问题
- 半监督训练器
  - 未区分学生/教师增强，二者对同一增强视图计算一致性，违背方法设计（SemiSupervisedTrainer.py:229–236）
  - 无标签数据加载使用与有标签相同的训练变换，包含依赖分割的变换（如区域/深监督下采样），不符合无标签流程（SemiSupervisedTrainer.py:155–174）
  - 一致性权重属性名不一致：脚本设置 `consistency_ramp_up_epochs`（train_semi_supervised.py:140），训练器使用 `consistency_rampup_starts/ends`（SemiSupervisedTrainer.py:93–97, 191–202），导致配置无效
  - 无标签数据路径允许缺省并回退到预处理目录（SemiSupervisedTrainer.py:128–135），与“强制要求明确传入”不符
  - 无标签迭代未采用与nnUNet相同的多线程封装，直接 `next(self.unlabeled_dataloader)`，与原生管线不一致（应使用 MultiThreadedAugmenter）
  - 构建无标签数据默认路径拼接不符合nnUNet v2的 `data_identifier` 约定（SemiSupervisedTrainer.py:131–133）
- 半监督数据加载器
  - `semi_supervised_dataloader.py` 复用有标签的 `transforms`，未提供无标签专用的去分割依赖的增强管线
- 双解码器回归训练
  - 训练器路径拼接错误，使用 `preprocessed_folder/data_identifier/data_identifier`，造成重复目录并引入修复逻辑（RegnnUNetTrainer.py:233–244）
  - 验证流程中误用未导入的 `nnUNetDataset`（RegnnUNetTrainer.py:766, 841），应使用本项目的 `RegnnUNetDataset`
  - 计划文件/网络对接未校验：回归微调阶段需在 plans 中声明 `DualDecoderRegCBAMUNet` 才能获得 `(seg, reg)` 输出
  - 细节稳健性：回归Loss与目标形状/类型对齐、深监督与回归头输出维度一致性需验证

## 修复方案
- 半监督训练器（nnunetv2/training/nnUNetTrainer/SemiSupervisedTrainer.py）
  - 新增 `get_unlabeled_transforms(patch_size, strength='weak'|'strong')`：仅图像增强，不引入任何 `seg` 相关变换；
    - weak：轻旋转/缩放，低概率噪声/模糊，保留镜像；
    - strong：提升旋转/缩放幅度，开启弹性形变、噪声、模糊、gamma/亮度/对比度（强度按配置augmentation_strength）；
  - 在 `initialize()` 中创建两个无标签增强管线并封装为两个数据流：
    - `unlabeled_loader_teacher = MultiThreadedAugmenter(nnUNetDataLoader(..., transforms=weak))`
    - `unlabeled_loader_student = MultiThreadedAugmenter(nnUNetDataLoader(..., transforms=strong))`
  - 在 `train_step`：分别从两路无标签流取 batch，教师用弱增强视图、学生用强增强视图，计算一致性损失；深监督时统一取最高分辨率头；
  - 统一一致性权重属性：移除 `consistency_rampup_starts/ends`，改为单一 `consistency_ramp_up_epochs` 和 `consistency_weight_max`（沿用配置中的 `semi_supervised.consistency_weight`）；按线性（或后续支持余弦/指数）调度；
  - 强制无标签路径：`initialize()` 若 `self.unlabeled_data_path` 为空则抛出异常并提示必须显式传入；
  - 修正默认路径拼接，改为使用 `self.configuration_manager.data_identifier` 与原生一致；
  - 无标签迭代按原生方式采用 MultiThreadedAugmenter 包裹，保持与 `dataloader_train` 一致的行为与性能；
- 半监督数据加载器（nnunetv2/training/dataloading/semi_supervised_dataloader.py）
  - 保留 `UnlabeledDataset` 生成 `dummy_seg` 的策略以兼容 `nnUNetDataLoader.generate_train_batch`；
  - 新增 `get_unlabeled_transforms(...)`（若选择在此处实现），并默认去除任何 `seg` 相关转换；
  - 明确 `create_semi_supervised_dataloader(...)` 仅返回原始图像流，增强交由训练器分别构建 weak/strong；
- 训练脚本与配置
  - `train_semi_supervised.py`：将命令行参数 `consistency_ramp_up_epochs` 映射到训练器的新属性名；
  - `run_semi_supervised_training.py`：在 `validate_config` 中将 `unlabeled_data_path` 设为必填（报错而非仅提示），并打印增强策略（strong/weak）摘要；
  - `semi_supervised_config.json`：沿用现有键名，半监督训练器读取 `semi_supervised.consistency_weight` 与 `consistency_ramp_up_epochs`；增强开关取 `augmentation.strong_augmentation_student / weak_augmentation_teacher`；
- 双解码器回归训练（nnunetv2/training/nnUNetTrainer/RegnnUNetTrainer.py）
  - 路径修复：`get_tr_and_val_datasets()` 使用 `self.preprocessed_dataset_folder` 直接作为数据根；移除重复目录探测逻辑；
  - 验证数据集：`perform_actual_validation` 全量替换为 `RegnnUNetDataset` 加载，并沿用已实现的 `RegnnUNetPredictor`；修复未导入类型；
  - 明确 plans 对接：在回归微调阶段的 plans 中声明网络类 `dynamic_network_architectures.architectures.dual_decoder_regression_cbamunet.DualDecoderRegCBAMUNet`，并设置 `regression_dim=1`、`enable_cross_attention=true`（按需）；
  - 回归Loss稳健性：保持 `DC_and_CE_and_Regression_loss` 的类型/形状对齐逻辑，训练与验证中确保 `(B, 1)` 的目标与输出一致；
  - 训练日志：记录 `seg_loss/reg_loss/total_loss` 与 `MSE/MAE`，并在 `save_checkpoint` 同步保存回归指标JSON（现有实现保留）；
- 双解码器网络（dynamic_network_architectures/.../dual_decoder_regression_cbamunet.py）
  - 交叉注意力索引与通道映射校验：当前通过反转 `regression_features` 与 `reg_stage_idx` 的映射保持分辨率对齐，保留实现但增加一致性检查；
  - 网络接口：维持 `(seg_outputs(list或tensor), reg_output)` 返回；`decoder.deep_supervision` 通过 `self.decoder = self.seg_decoder` 保持nnUNet切换兼容；

## 交付与验证
- 半监督阶段
  - 在 `SEMI_SUPERVISED_TRAINING_GUIDE.md` 所列指标中新增：`consistency_weight` 实际曲线与 `loss_consistency` 是否随 ramp-up 正常上升/下降；
  - 运行少量 epoch 验证：教师与学生预测的差异度是否合理（弱/强增强），一致性损失是否稳定；
- 回归微调阶段
  - 使用 `RegnnUNetPredictor` 做验证：输出 `(logits, regression)`；检查 `mse/mae` 写入与日志打印；
  - 快速过拟合测试（少量样本+大迭代）：确保回归头与分割头均能下降；

## 改动文件
- `nnunetv2/training/nnUNetTrainer/SemiSupervisedTrainer.py`
- `nnunetv2/training/dataloading/semi_supervised_dataloader.py`
- `nnunetv2/training/nnUNetTrainer/train_semi_supervised.py`
- `run_semi_supervised_training.py`
- `nnunetv2/training/nnUNetTrainer/RegnnUNetTrainer.py`
- （按需）`dynamic-network-architectures/.../dual_decoder_regression_cbamunet.py`

## 预计影响
- 半监督阶段训练稳定性与指标解释性显著提升（强/弱增强分离与 ramp-up 生效）
- 无标签数据管线与nnUNet原生行为一致（多线程augmenter、无 `seg` 依赖增强）
- 回归微调可稳定运行并生成可用的MSE/MAE指标与回归输出

请确认以上修复方案，我将按此逐步实施并在每一步完成后验证与回报。